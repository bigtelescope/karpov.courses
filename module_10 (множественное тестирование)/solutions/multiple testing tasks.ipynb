{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a970442f",
   "metadata": {},
   "source": [
    "## Задача 1. Количество параллельных экспериментов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437546a",
   "metadata": {},
   "source": [
    "Сколько несовместных независимых экспериментов можно запустить одновременно, если за время эксперимента собираем 10000 наблюдений?\n",
    "\n",
    "Если решаем запустить 10 экспериментов, то на каждый эксперимент можно выделить по 1000 наблюдений, размер групп будет равен 500.\n",
    "\n",
    "Параметры экспериментов:\n",
    "\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82951b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3e3b2",
   "metadata": {},
   "source": [
    "### авторское решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73fc48",
   "metadata": {},
   "source": [
    "тк знаем стандартное отклонение распределения, размер эффекта, и предельные ошибки 1 и 2 рода, то можем оценить минимальный размер группы для получения эффекта выше как мде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39dfd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 558/10000 [00:00<00:03, 2789.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size = 233\n",
      "count_exp = 21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2882.16it/s]\n",
      "  3%|▎         | 289/10000 [00:00<00:03, 2889.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 21\n",
      "sample_size = 238\n",
      "оценка вероятности ошибки I рода = 0.0517\n",
      "  доверительный интервал = [0.0474, 0.0560]\n",
      "оценка вероятности ошибки II рода = 0.1027\n",
      "  доверительный интервал = [0.0968, 0.1086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2918.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 22\n",
      "sample_size = 227\n",
      "оценка вероятности ошибки I рода = 0.0535\n",
      "  доверительный интервал = [0.0491, 0.0579]\n",
      "оценка вероятности ошибки II рода = 0.1160\n",
      "  доверительный интервал = [0.1097, 0.1223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# параметры эксперимента\n",
    "total_size = 10000\n",
    "mean_ = 100\n",
    "std_ = 10\n",
    "effect = 0.03\n",
    "alpha = 0.05\n",
    "beta = 0.1\n",
    "\n",
    "# оценка размера группы через эффект и мде\n",
    "def estimate_sample_size(effect, std, alpha, beta):\n",
    "    \n",
    "    # обратная функция распределения для альфы\n",
    "    t_alpha = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    \n",
    "    # обратная функция распределения для беты\n",
    "    t_beta = stats.norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    \n",
    "    # сумма стандартных отклонений\n",
    "    var = 2 * std ** 2\n",
    "    \n",
    "    # оценка минимального размера группы\n",
    "    sample_size = int((t_alpha + t_beta) ** 2 * var / (effect ** 2))\n",
    "    \n",
    "    return sample_size\n",
    "\n",
    "\n",
    "# оценим необходимый размер групп\n",
    "sample_size = estimate_sample_size(effect * 100, 10, alpha, beta)\n",
    "print(f'sample_size = {sample_size}')\n",
    "\n",
    "# вычислим количество экспериментов\n",
    "count_exp = total_size / (sample_size * 2)\n",
    "print(f'count_exp = {count_exp:0.1f}')\n",
    "\n",
    "\n",
    "def estimate_ci_bernoulli(p, n, alpha=0.05):\n",
    "    \"\"\"Доверительный интервал для Бернуллиевской случайной величины.\"\"\"\n",
    "    t = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    std_n = np.sqrt(p * (1 - p) / n)\n",
    "    return p - t * std_n, p + t * std_n\n",
    "\n",
    "# Проверим, что при 21 эксперимента ошибки контролируются на заданных уровнях, а при 22 экспериментах нет.\n",
    "\n",
    "for count_exp in [21, 22]:\n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in tqdm(range(10000)):\n",
    "        a, b = np.random.normal(mean_, std_, (2, sample_size,))\n",
    "        b_effect = b * (1 + effect)\n",
    "        errors_aa.append(stats.ttest_ind(a, b).pvalue < alpha)\n",
    "        errors_ab.append(stats.ttest_ind(a, b_effect).pvalue >= alpha)\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    ci_first = estimate_ci_bernoulli(estimated_first_type_error, len(errors_aa))\n",
    "    ci_second = estimate_ci_bernoulli(estimated_second_type_error, len(errors_ab))\n",
    "    print(f'count_exp = {count_exp}')\n",
    "    print(f'sample_size = {sample_size}')\n",
    "    print(f'оценка вероятности ошибки I рода = {estimated_first_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_first[0]:0.4f}, {ci_first[1]:0.4f}]')\n",
    "    print(f'оценка вероятности ошибки II рода = {estimated_second_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_second[0]:0.4f}, {ci_second[1]:0.4f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ef1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size = 233\n",
    "# count_exp = 21.5\n",
    "\n",
    "# count_exp = 21\n",
    "# sample_size = 238\n",
    "# оценка вероятности ошибки I рода = 0.0461\n",
    "#   доверительный интервал = [0.0420, 0.0502]\n",
    "# оценка вероятности ошибки II рода = 0.1018\n",
    "#   доверительный интервал = [0.0959, 0.1077]\n",
    "\n",
    "# count_exp = 22\n",
    "# sample_size = 227\n",
    "# оценка вероятности ошибки I рода = 0.0485\n",
    "#   доверительный интервал = [0.0443, 0.0527]\n",
    "# оценка вероятности ошибки II рода = 0.1165\n",
    "#   доверительный интервал = [0.1102, 0.1228]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574cfc66",
   "metadata": {},
   "source": [
    "### мое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b677da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры нормального распределения\n",
    "mean = 100 \n",
    "std_dev = 10\n",
    "\n",
    "# всего наблюдений\n",
    "N = 10000 \n",
    "alpha = 0.05\n",
    "beta = 0.1\n",
    "uplift = 1.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa37981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(groups_cnt):\n",
    "    single_size = int(N / groups_cnt)\n",
    "    \n",
    "    exp_sample = np.random.normal(loc=mean, scale=std_dev, size=single_size)\n",
    "    random.shuffle(exp_sample)\n",
    "    \n",
    "    total_users = len(exp_sample)\n",
    "    half_size = total_users // 2\n",
    "    \n",
    "    test_distr = exp_sample[:half_size]\n",
    "    control_distr = exp_sample[half_size:]\n",
    "    \n",
    "#     print(len(test_distr), round(test_distr.mean(), 2))\n",
    "#     print(len(control_distr), round(control_distr.mean(), 2))\n",
    "    _, aa_pvalue = stats.ttest_ind(control_distr, test_distr)\n",
    "    \n",
    "    test_distr = test_distr * uplift\n",
    "#     print(len(test_distr), round(test_distr.mean(), 2))\n",
    "#     print(len(control_distr), round(control_distr.mean(), 2))\n",
    "#     print(round(test_distr.mean() / control_distr.mean(), 2))\n",
    "    _, ab_pvalue = stats.ttest_ind(control_distr, test_distr)\n",
    "\n",
    "    return aa_pvalue, ab_pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d0a0841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.05 0.0479 0.1 0.0\n",
      "3 0.05 0.0484 0.1 0.0\n",
      "4 0.05 0.0498 0.1 0.0\n",
      "5 0.05 0.052 0.1 0.0\n",
      "6 0.05 0.0516 0.1 0.0\n",
      "7 0.05 0.0507 0.1 0.0002\n",
      "8 0.05 0.0489 0.1 0.0006\n",
      "9 0.05 0.0501 0.1 0.0011\n",
      "10 0.05 0.0534 0.1 0.0034\n",
      "11 0.05 0.0482 0.1 0.0065\n",
      "12 0.05 0.0524 0.1 0.0123\n",
      "13 0.05 0.0463 0.1 0.0156\n",
      "14 0.05 0.0505 0.1 0.0227\n",
      "15 0.05 0.0487 0.1 0.0303\n",
      "16 0.05 0.0491 0.1 0.0426\n",
      "17 0.05 0.0461 0.1 0.0522\n",
      "18 0.05 0.0484 0.1 0.0639\n",
      "19 0.05 0.0485 0.1 0.0741\n",
      "20 0.05 0.0493 0.1 0.0897\n",
      "21 0.05 0.0494 0.1 0.1026\n",
      "22 0.05 0.052 0.1 0.1216\n",
      "23 0.05 0.0477 0.1 0.1332\n",
      "24 0.05 0.0509 0.1 0.1468\n",
      "25 0.05 0.0541 0.1 0.1664\n",
      "26 0.05 0.0506 0.1 0.1724\n",
      "27 0.05 0.0479 0.1 0.1876\n",
      "28 0.05 0.0493 0.1 0.2029\n",
      "29 0.05 0.0509 0.1 0.2232\n"
     ]
    }
   ],
   "source": [
    "for count_sample in range(2, 30):\n",
    "    \n",
    "    aa_pvalues = []\n",
    "    ab_pvalues = []\n",
    "    \n",
    "    for _ in range(10000):\n",
    "        aa_pvalue, ab_pvalue = create_groups(count_sample)\n",
    "        aa_pvalues.append(aa_pvalue)\n",
    "        ab_pvalues.append(ab_pvalue)\n",
    "        \n",
    "    # ошибка первого рода = доля прокрашенных аа тестов\n",
    "    first_type_sample = round(sum([1 if pval_aa < alpha else 0 for pval_aa in aa_pvalues]) / len(aa_pvalues), 5)\n",
    "    \n",
    "    # ошибка второго рода = доля непрокрашенных аб-тестов\n",
    "    second_type_sample = round(1 - sum([1 if pval_ab < alpha else 0 for pval_ab in ab_pvalues]) / len(ab_pvalues), 5)\n",
    "    \n",
    "    print(count_sample, alpha, first_type_sample, beta, second_type_sample)\n",
    "#     if first_type_sample > alpha or second_type_sample > beta:\n",
    "#         print(count_sample, alpha, first_type_sample, beta, second_type_sample)\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eaa839",
   "metadata": {},
   "source": [
    "## Задача 2. Количество параллельных экспериментов — 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921313e6",
   "metadata": {},
   "source": [
    "Задача похожа на предыдущую, только теперь решение принимается не независимо для каждого эксперимента.\n",
    "Например, у нас есть 5 текстов для маркетинговой рассылки, хотим проверить, какой эффективнее работает и работает ли вообще.\n",
    "Алгоритм будет следующий:\n",
    "\n",
    "1. Формируем непересекающиеся контрольные и экспериментальные группы для каждого из 5 вариантов.\n",
    "2. Проводим параллельно 5 экспериментов.\n",
    "3. С помощью метода Холма определяем, в каких экспериментах были статистически значимые отличия.\n",
    "4. Если значимых отличий не обнаружено, то говорим, что эффекта нет, все варианты отклоняем.\n",
    "5. Если значимые отличия обнаружены, то из вариантов со значимым эффектом выбираем вариант с наименьшим значением p-value, будем использовать его.\n",
    "\n",
    "Будем считать, что совершена ошибка I рода, если найдены значимые отличия, когда на самом деле их не было ни в одном из вариантов.\n",
    "\n",
    "Будем считать, что совершена ошибка II рода, если:\n",
    "- либо не найдено значимых отличий, когда на самом деле они были;\n",
    "- либо выбранный для дальнейшего использования вариант на самом деле был без эффекта, при этом были варианты с эффектом.\n",
    "\n",
    "Параметры экспериментов:\n",
    "\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Замечание: при оценке вероятности ошибки II рода нужно рассматривать худший сценарий, когда эффект есть только в одном из экспериментов. Чем в большем количестве экспериментов будет эффект, тем меньше будет вероятность ошибки II рода.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651caac8",
   "metadata": {},
   "source": [
    "### мое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6a09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 10000\n",
    "mean_ = 100\n",
    "std_ = 10\n",
    "effect = 0.03\n",
    "alpha = 0.05\n",
    "beta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d13fcfcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1008.49it/s]\n",
      "  1%|          | 77/10000 [00:00<00:13, 761.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 2\n",
      "0.048 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 755.16it/s]\n",
      "  1%|          | 58/10000 [00:00<00:17, 579.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 3\n",
      "0.0512 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 601.47it/s]\n",
      "  0%|          | 50/10000 [00:00<00:20, 491.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 4\n",
      "0.0501 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 498.21it/s]\n",
      "  0%|          | 43/10000 [00:00<00:23, 427.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 5\n",
      "0.0463 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 429.08it/s]\n",
      "  0%|          | 37/10000 [00:00<00:26, 369.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 6\n",
      "0.0499 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 372.22it/s]\n",
      "  0%|          | 34/10000 [00:00<00:29, 333.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 7\n",
      "0.0492 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 332.08it/s]\n",
      "  0%|          | 31/10000 [00:00<00:32, 306.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 8\n",
      "0.0477 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:33<00:00, 299.14it/s]\n",
      "  0%|          | 29/10000 [00:00<00:34, 285.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 9\n",
      "0.0459 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:36<00:00, 273.62it/s]\n",
      "  0%|          | 26/10000 [00:00<00:39, 252.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 10\n",
      "0.0538 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:39<00:00, 253.16it/s]\n",
      "  0%|          | 24/10000 [00:00<00:41, 237.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 11\n",
      "0.0522 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 232.53it/s]\n",
      "  0%|          | 22/10000 [00:00<00:46, 216.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 12\n",
      "0.0499 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:46<00:00, 213.28it/s]\n",
      "  0%|          | 21/10000 [00:00<00:48, 206.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 13\n",
      "0.0489 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:50<00:00, 199.78it/s]\n",
      "  0%|          | 18/10000 [00:00<00:57, 174.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 14\n",
      "0.0454 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:53<00:00, 187.46it/s]\n",
      "  0%|          | 19/10000 [00:00<00:54, 183.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 15\n",
      "0.049 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:56<00:00, 176.97it/s]\n",
      "  0%|          | 17/10000 [00:00<01:00, 166.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 16\n",
      "0.0465 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:59<00:00, 167.32it/s]\n",
      "  0%|          | 16/10000 [00:00<01:05, 151.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 17\n",
      "0.0482 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:02<00:00, 158.74it/s]\n",
      "  0%|          | 16/10000 [00:00<01:06, 151.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 18\n",
      "0.0527 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:06<00:00, 151.04it/s]\n",
      "  0%|          | 15/10000 [00:00<01:08, 145.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 19\n",
      "0.049 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:09<00:00, 144.70it/s]\n",
      "  0%|          | 15/10000 [00:00<01:09, 143.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 20\n",
      "0.0507 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:12<00:00, 137.93it/s]\n",
      "  0%|          | 14/10000 [00:00<01:16, 130.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 21\n",
      "0.0454 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:16<00:00, 130.72it/s]\n",
      "  0%|          | 13/10000 [00:00<01:17, 128.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 22\n",
      "0.0483 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:19<00:00, 125.11it/s]\n",
      "  0%|          | 13/10000 [00:00<01:18, 126.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 23\n",
      "0.0466 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:23<00:00, 120.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 24\n",
      "0.0498 10000\n",
      "0.0 10000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for count_exp in range(2, 25):\n",
    "    \n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    \n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in tqdm(range(10000)):\n",
    "        # создаю словарь из count_exp экспов для замеров по аа-тестам\n",
    "        active_aa_exps = {}\n",
    "        \n",
    "        # создаю словарь из count_exp экспов для замеров по аb-тестам\n",
    "        active_ab_exps = {}\n",
    "        \n",
    "        # генерю тест и контроль для каждого экспа\n",
    "        for exp_num in range(count_exp):\n",
    "            \n",
    "            # каждому номеру теста соответствует список с aa_pval, alpha_aa_upd\n",
    "            active_aa_exps[exp_num] = []\n",
    "            \n",
    "            # каждому номеру теста соответствует список с ab_pval, alpha_ab_upd\n",
    "            active_ab_exps[exp_num] = []\n",
    "            \n",
    "            # генерю тест и контроль для аа-теста данной итерации\n",
    "            a, b = np.random.normal(mean_, std_, (2, sample_size,))\n",
    "            \n",
    "            # считаю pvalue для аа-теста данной итерации\n",
    "            _, aa_pval = stats.ttest_ind(a, b)\n",
    "            active_aa_exps[exp_num].append(aa_pval)\n",
    "            \n",
    "            # для первого теста из count_exp добавляем эффект для замеров ошибки 2 рода\n",
    "            if exp_num == 0:\n",
    "                b = b * (1 + effect)\n",
    "                active_ab_exps[exp_num].append('has_real_effect')\n",
    "            else:\n",
    "                active_ab_exps[exp_num].append('no_real_effect')\n",
    "                \n",
    "            # считаю pvalue для аb-теста данной итерации\n",
    "            _, ab_pval = stats.ttest_ind(a, b)\n",
    "            active_ab_exps[exp_num].append(ab_pval)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # ранжирую по pvalue для поиска ошибок 1 рода для этой итерации\n",
    "        active_aa_exps = dict(sorted(active_aa_exps.items(), key=lambda item: item[1]))\n",
    "        index = 1\n",
    "        for key in active_aa_exps:\n",
    "            # cохраняю индивидуальные pvalue для поиска ошибок 1 рода для этой итерации\n",
    "            local_alpha = alpha / (count_exp + 1 - index)\n",
    "            active_aa_exps[key].append(local_alpha)\n",
    "            index += 1 \n",
    "\n",
    "        # складываю результат поиска ошибок 1 рода для этой итерации\n",
    "        # если хотя бы в 1 тесте из списка доступных найден эффект - кладем 1 в errors_aa\n",
    "        # если в списке доступных нигде не найден эффект - кладем 0 в errors_aa\n",
    "        available_tests_list = list(active_aa_exps.keys()).copy()\n",
    "        found_error_1_type = 0\n",
    "        for i in range(len(available_tests_list)):\n",
    "            # если данный скорректированный pvalue больше полученного для аа-теста, возводим флаг и прерываемся\n",
    "            if active_aa_exps[available_tests_list[i]][1] > active_aa_exps[available_tests_list[i]][0]:\n",
    "                found_error_1_type = 1\n",
    "                break\n",
    "        errors_aa.append(found_error_1_type)\n",
    "\n",
    "        \n",
    "        # ранжирую по pvalue для поиска ошибок 2 рода для этой итерации\n",
    "        active_ab_exps = dict(sorted(active_ab_exps.items(), key=lambda item: item[1]))\n",
    "        index = 1\n",
    "        for key in active_ab_exps:\n",
    "            # cохраняю индивидуальные pvalue для поиска ошибок 2 рода для этой итерации\n",
    "            local_alpha = alpha / (count_exp + 1 - index)\n",
    "            active_ab_exps[key].append(local_alpha)\n",
    "            index += 1 \n",
    "\n",
    "            \n",
    "        # складываю результат поиска ошибок 2 рода для этой итерации\n",
    "        # если в тесте с эффектом скорректированный pvalue меньше полученного для аb-теста, кладем 1 в errors_ab\n",
    "        # если найден эффект в тесте без эффекта, кладем 1 в errors_ab\n",
    "        # в противном случае кладем 0 в errors_ab\n",
    "        available_tests_list = list(active_ab_exps.keys()).copy()\n",
    "        found_error_2_type = 0\n",
    "        for i in range(len(available_tests_list)):\n",
    "            # если в тесте с эффектом \n",
    "            if active_ab_exps[available_tests_list[i]][1] == 'has_real_effect':\n",
    "                # скорректированный pvalue меньше полученного для аb-теста\n",
    "                if active_ab_exps[available_tests_list[i]][2] <= active_ab_exps[available_tests_list[i]][1]:\n",
    "                    # возводим флаг и прерываемся\n",
    "                    found_error_2_type = 1\n",
    "                    break\n",
    "                \n",
    "            # если в тесте без эффекта\n",
    "            elif active_ab_exps[available_tests_list[i]][1] == 'no_real_effect':\n",
    "                # пограничное скорректированное значение pvalue больше полученного pvalue\n",
    "                if active_ab_exps[available_tests_list[i]][2] > active_ab_exps[available_tests_list[i]][1]:\n",
    "                    # возводим флаг и прерываемся\n",
    "                    found_error_2_type = 1\n",
    "                    break\n",
    "        errors_ab.append(found_error_2_type)\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    \n",
    "    print('count_exp =', count_exp)\n",
    "    print(estimated_first_type_error, len(errors_aa))\n",
    "    print(estimated_second_type_error, len(errors_ab), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfb062",
   "metadata": {},
   "source": [
    "### авторское решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a35955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:42<00:00, 233.48it/s]\n",
      "  0%|          | 23/10000 [00:00<00:43, 226.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 12\n",
      "sample_size = 416\n",
      "оценка вероятности ошибки I рода = 0.0509\n",
      "  доверительный интервал = [0.0466, 0.0552]\n",
      "оценка вероятности ошибки II рода = 0.0866\n",
      "  доверительный интервал = [0.0811, 0.0921]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:45<00:00, 218.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 13\n",
      "sample_size = 384\n",
      "оценка вероятности ошибки I рода = 0.0499\n",
      "  доверительный интервал = [0.0456, 0.0542]\n",
      "оценка вероятности ошибки II рода = 0.1202\n",
      "  доверительный интервал = [0.1138, 0.1266]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def method_holm(pvalues, alpha=0.05):\n",
    "    \"\"\"Применяет метод Холма для проверки значимости изменений.\n",
    "    \n",
    "    pvalues - List[float] - список pvalue.\n",
    "    alpha - float, уровень значимости.\n",
    "    return - np.array, массив из нулей и единиц, 0 - эффекта нет, 1 - эффект есть.\n",
    "    \"\"\"\n",
    "    m = len(pvalues)\n",
    "    array_alpha = np.arange(m, 0, -1)\n",
    "    array_alpha = alpha / array_alpha\n",
    "    sorted_pvalue_indexes = np.argsort(pvalues)\n",
    "    res = np.zeros(m)\n",
    "    for idx, pvalue_index in enumerate(sorted_pvalue_indexes):\n",
    "        pvalue = pvalues[pvalue_index]\n",
    "        alpha_ = array_alpha[idx]\n",
    "        if pvalue < alpha_:\n",
    "            res[pvalue_index] = 1\n",
    "        else:\n",
    "            break\n",
    "    res = res.astype(int)\n",
    "    return res\n",
    "\n",
    "# Проверим, что при 12 эксперимента ошибки контролируются на заданных уровнях, а при 13 экспериментах нет.\n",
    "\n",
    "for count_exp in [12, 13]:\n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in tqdm(range(10000)):\n",
    "        list_ab_values = [\n",
    "            np.random.normal(mean_, std_, (2, sample_size))\n",
    "            for _ in range(count_exp)\n",
    "        ]\n",
    "        # синтетический А/А тест\n",
    "        pvalues = [stats.ttest_ind(a, b).pvalue for a, b in list_ab_values]\n",
    "        aa_with_effect = method_holm(pvalues, alpha)\n",
    "        errors_aa.append(np.sum(aa_with_effect) > 0)\n",
    "\n",
    "        # Синтетический А/Б тест.\n",
    "        # Достаточно проверить случай, когда эффект есть лишь в одном из экспериментов,\n",
    "        # так как при наличии эффектов в большем кол-ве экспериментов ошибок II рода станет меньше.\n",
    "        # Добавим эффект в первый эксперимент (не важно в какой добавлять, так как данные случайные)\n",
    "        list_ab_values[0][1] *= 1 + effect\n",
    "        pvalues = [stats.ttest_ind(a, b).pvalue for a, b in list_ab_values]\n",
    "        ab_with_effect = method_holm(pvalues, alpha)\n",
    "        if np.sum(ab_with_effect) == 0:\n",
    "            # если эффектов не найдено, то это ошибка\n",
    "            errors_ab.append(True)\n",
    "        else:\n",
    "            # если эффектов найден где его нет, то это ошибка\n",
    "            errors_ab.append(np.min(pvalues) != pvalues[0])\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    ci_first = estimate_ci_bernoulli(estimated_first_type_error, len(errors_aa))\n",
    "    ci_second = estimate_ci_bernoulli(estimated_second_type_error, len(errors_ab))\n",
    "    print(f'count_exp = {count_exp}')\n",
    "    print(f'sample_size = {sample_size}')\n",
    "    print(f'оценка вероятности ошибки I рода = {estimated_first_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_first[0]:0.4f}, {ci_first[1]:0.4f}]')\n",
    "    print(f'оценка вероятности ошибки II рода = {estimated_second_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_second[0]:0.4f}, {ci_second[1]:0.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443dfb0",
   "metadata": {},
   "source": [
    "Получили, что при 12 экспериментах всё корректно, а при 13 экспериментах вероятность ошибки II рода больше 0.1.\n",
    "\n",
    "Получается, если мы проводим множественное тестирование, то за раз можем проверить меньшее количество гипотез, чем если бы проверяли независимые гипотезы. Это логично, так как мы предъявляем более строгое требование к вероятностям ошибок первого рода при множественном тестировании. Из-за этого наш критерий дополнительно перестраховывается и реже говорит, что эффект есть, что приводит к увеличению вероятности ошибок II рода. Компенсировать увеличение вероятности ошибок II рода приходится за счёт увеличения размера групп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf947b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
